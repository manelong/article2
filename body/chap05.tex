\chapter{帧间一致性建模的体育时空动作检测算法研究} 

\label{cha:fifthsection}

第三章从特征增强的角度出发，利用多模态大模型构建外部知识库，旨在为复杂的
体育运动时空动作检测补充丰富的语义信息。而本章专注于时空特征的
深度挖掘，致力于提升模型内在的时空特征一致性建模能力。鉴于体育动作具有运动
剧烈、位移显著以及与场景元素高度耦合等特性，本章提出了一种基于动作实例特征
引导的时空一致性建模方法。该方法通过生成与动作实例相关的动作管查询来引导
时空特征的一致性建模，从而有效提升模型在复杂体育场景下的检测性能。

本章的组织结构安排如下：4.1节首先剖析现有方法在时空特征一致性建模方面存在的
局限性，并阐述本章的研究动机与思路；4.2节详细介绍模型的整体架构；随后，4.3节、
4.4节和4.5节分别阐述本章设计的三个核心模块：动作实例相关的动作管生成模块、实例
特征引导的自适应采样模块以及解耦时空交叉注意力模块；最后，4.6节介绍实验设置并
对实验结果进行深入分析，4.7节对本章工作进行总结。

\section{引言}

在时空动作检测任务中，时空一致性建模主要涵盖两个核心维度：（1）同一动作实例
在不同时间步上的帧间关联；（2）与动作实例相关的时空上下文在时间维度上的深度特征挖掘。

帧间实例关联是时空动作检测面临的关键挑战之一。早期研究通常基于帧级检测结果，将
帧间关联视为独立的后处理或前处理步骤，主要依赖相邻帧检测框的空间重叠度（IoU）和视觉
相似性进行连接。然而，这类方法人为割裂了检测与关联过程，忽略了跨帧特征一致性建模的重
要性。随后，部分工作尝试设计3D Anchor以实现特征层面的关联，但这些方法通常建立在小位移
假设之上，预定义的锚框在时序维度缺乏灵活性且优化困难，限制了对时空上下文的充分挖掘。
近年来，基于查询（Query-based）的方法利用动作管查询和时序自注意力机制，能够自适应地
实现帧间目标的一致性关联，展现出优越的性能与潜力。
图\ref{Fig4-1}展示了现有几种主流帧间动作关联方法的示意图。

\begin{figure}[!htbp] 
    \centering 
    \includegraphics[width=\textwidth]{figures/关联方式.png} 
    \caption{主流帧间动作关联方法示意图}\label{Fig4-1} 
\end{figure}

具体而言，Tuber提出的动作管查询设计验证了时空正交解耦的自注意力机制有助于在查询层
面实现同一动作实例的一致性关联。然而，Tuber完全依赖于Transformer架构的长程建模能力，
缺乏对跨帧时空特征一致性的显式引导。在面对复杂运动场景时，这种隐式建模存在信息瓶颈，
且动作解码器中全局时空注意力的计算开销巨大。在此基础上，STAR设计了正交解耦的交叉注意力
机制，限制动作管查询仅与当前时间步的特征进行交互。虽然这缓解了计算负担，但同样未解决跨
帧特征一致性显式建模的问题。ART方法则利用人物检测器和RoI Align聚合关键帧特征，经时序
扩展生成动作管查询，但该查询仅包含关键帧的外观先验，缺乏对运动趋势和场景上下文等关键信
息的利用。

综上所述，受限于体育运动的剧烈性和环境复杂性，现有基于查询的方法在处理体育时空动作检测时
仍面临两大难题：（1）动作实例间的帧间信息关联鲁棒性不足，难以适应大位移和剧烈形变；（2）对
时空上下文特征的挖掘存在局限，导致对相似体育动作的辨别能力较弱。

针对上述问题，本章提出了一种基于动作实例特征引导的帧间一致性建模方法
（Instance-guided Spatiotemporal Consistency Modeling, ISCM）。
具体来说，为了增强帧间动作实例关联，设计了动作实例感知模块（Action Instance-Aware Module, AIAM）。
该模块通过从全局时空特征中挖掘潜在的动作实例相关特征，并以此引导解码器中的信息聚合过程，
从而保证了时间维度上的主题一致性。为了提升时空上下文特征的挖掘能力，本章进一步设计了实例
特征引导的自适应采样模块（Instance-guided Adaptive Sampling Module, IASM）以及解耦时空交叉
注意力模块（Decoupled Spatiotemporal Cross-Attention Module, DSTA）。前者通过自适应采样
策略，灵活地提取与聚合时空特征图中与动作高度相关的特征；后者则通过解耦机制增强了模型对
局部细节的感知能力。

本章在UCF101-24和Multisports数据集上与现有方法进行了对比实验，并通过各模块间的消融实验，
验证了所提方法的有效性。 本章的主要贡献包括以下三点：
（1）提出了一种基于动作实例特征引导的时空一致性建模框架（ISCM）。针对体育场景下运动剧烈、位移显著
导致的问题，本章打破了以往隐式建模的局限，提出利用生成的动作实例相关动作管查询，显式引导
时空特征的一致性建模。

（2）设计了动作实例感知模块（AIAM），显著增强了帧间动作关联的鲁棒性。 为了解决同一实例在不同时间步
的关联问题，该模块通过挖掘全局时空特征中的潜在动作主题，引导解码器的信息聚合过程。这保证了
动作管查询在时间维度上的主题一致性，有效应对了大位移和剧烈形变带来的挑战。

（3）提出了实例特征引导的自适应采样模块（IASM）与解耦时空交叉注意力模块（DSTA），提升了对时空上下文特征的
挖掘能力。针对相似体育动作辨别难的问题，通过自适应采样策略灵活聚焦与动作高度相关的特征区域，
并结合解耦的时空交叉注意力机制，增强了模型对局部细节和时空动态的感知能力。

\section{方法框架}
\section{模型整体架构}

\begin{figure}[!htbp] 
    \centering 
    \includegraphics[width=\textwidth]{figures/工作2整体.png} 
    \caption{基于动作实例特征引导的帧间一致性建模方法整体框架}\label{Fig4-2} 
\end{figure}
如图\ref{Fig4-2}所示，本章提出的基于动作实例特征引导的帧间一致性建模方法
整体架构由视频特征提取、实例相关动作管查询生成、时空动作解码器以及检测头四个核心部分组成。
在时空特征提取阶段，首先利用3D CNN作为骨干网络从输入视频片段$X \in \mathbb{R}^{T \times H \times W \times 3}$
中提取多尺度的时空视觉特征；为了适配后续的时空一致性建模并防止时序细节丢失，
特征提取过程中采用了双线性插值策略，强制保证所有尺度的特征图在时间维度上保持原始分辨率$T$，
从而构建出特征金字塔 $\mathcal{S} =\{S_i\}_{i=3}^{5}$，其中第 $i$ 层特征图
$S_i \in \mathbb{R}^{T \times h_i \times w_i \times c_i}$。紧接着，
为了解决随机初始化查询难以捕捉复杂运动的问题，实例相关动作管查询生成模块引入了
动作实例感知模块（AIAM），该模块以语义信息最丰富的深层特征$S_5$为输入，
提取出表征潜在动作实例的静态特征$Q_{inst} \in \mathbb{R}^{N \times C}$（$N$ 为查询数量）；
随后，将 $Q_{inst}$ 在时间维度上进行复制与时序扩展，并叠加3D位置编码，生成贯穿整个时序的动作
管查询 $Q_{tube} \in \mathbb{R}^{N \times T \times C}$。在时空动作解码器中，这些动作管
查询首先经过正交分解的自注意力机制（Factorised Self Attention，FSA）进行内部交互，更新后的查询随即用于生
成采样点偏移量；利用该
偏移量，模型在多尺度特征图 $\mathcal{S}$ 上执行自适应采样，提取出与当前动作实例高度相关的
时空特征 $S_{sampled} \in \mathbb{R}^{N \times n \times T \times c_i}$（其中 $n$ 为
采样点数量）；最后，通过解耦时空交叉注意力模块（DSTA）
计算查询与采样特征 $S_{sampled}$ 之间的交互，将关键的视频上下文信息注入动作管查询中，得
到更新后的特征 $Q_{update}$。经过解码器的多层迭代更新后，最终的动作管特征被送入检测头，该模块由
三个特定的分支组成：首先是一个动作分类头，用于预测动作实例的类别，输出维度为
$\hat{y}_{cls} \in \mathbb{R}^{N \times K+1}$（$K$ 为类别数）；
其次是两个前馈神经网络（FFN），分别负责时序边界判断和矩形框回归，前者输出时序边界概率
$\hat{y}_{bound} \in \mathbb{R}^{N \times T}$，后者输出归一化的时空边界框坐标
$\hat{y}_{box} \in \mathbb{R}^{N \times 4 \times T}$，从而实现对时空动作的精确定位与识别。

\section{动作实例相关动作管查询生成}

为了增强帧间动作实例关联的鲁棒性，本节设计了动作实例感知型动作管查询生成模块，该模块包含两个关键部分：
动作实例感知模块（AIAM）和时序拓展环节，具体结构如图\ref{Fig4-3}所示。前者旨在基于全局时空特征挖掘
潜在的动作实例相关特征，并通过注意力机制将这些特征注入到动作查询中，实现视频片段中动作实例信息的预提取。
这使得动作感知查询能够包含丰富的动作实例先验，从而指导后续的时空特征采样和聚合。后者则负责将动作实例
感知特征在时间维度上进行扩展，并通过补充位置编码信息注入时序位置先验，最终生成既包含动作实例语义，又能
感知时间维度运动变化的动作管查询。下面首先介绍AIAM。

\begin{figure}[!htbp] 
    \centering 
    \includegraphics[width=0.6\textwidth]{figures/工作2模块1.png} 
    \caption{动作实例相关的动作管查询生成模块}\label{Fig4-3} 
\end{figure}

现有的时空动作检测方法（如TubeR、STAR）中，动作管查询通常采用随机初始化，或仅随机初始化空间查询后在
时间维度上复制。这种方式忽略了视频片段中潜在的特定动作实例信息，导致查询难以迅速捕捉复杂运动特征。
另有一些方法（如 ART、STMixer）依赖预生成的关键帧特征，忽略了跨帧时空特征一致性的显式建模，导致在
复杂运动场景下，动作实例间的帧间关联鲁棒性不足。为了解决这个问题，本节设计了动作实例感知模块（AIAM）。
对于由视觉特征提取器得到的深层时空特征$S_5 \in \mathbb{R}^{T \times h_5 \times w_5 \times C_5}$，
在AIAM中，首先通过一个轻量的动作提取模块 $\mathcal{F}_{ext}(\cdot)$ 对时空特征进行增强。该模块由
三个堆叠的（Conv3D, BN3D, ReLU）单元组成，并引入残差连接以缓解梯度消失问题，增强后的特征$F_{enh}$计算如下：
\begin{equation}
    F_{enh} = \mathcal{F}{ext}(S_5) + S_5
\end{equation}
随后，为了保留丰富的时空细节以供后续查询，模型并未对$F{enh}$进行全局池化压缩，而是将其在时空维度上进行展平，
得到序列化的动作实例特征$F_{inst}$，表示为：
\begin{equation}
    F_{inst} = \text{Flatten}(F_{enh}) \in \mathbb{R}^{L \times C_5}
\end{equation}
其中，$L = T \times h_5 \times w_5$ 表示时空特征序列的长度，$C_5$为特征通道数。
接着，为了从 $F_{inst}$ 中解耦出 $N$ 个独立的潜在动作实例，模型定义了一组可学习的动作感知查询原型
$Q_{proto} \in \mathbb{R}^{N \times C_5}$。AIAM 利用多头注意力模块建立动作原型查询与时空特征之间的交互，
在计算过程中将$Q_{proto}$作为查询，将包含丰富时空细节的$F_{inst}$同时作为键和值。
形式上，对于第 $i$ 个注意力头，注意力权重的计算过程如下：
\begin{equation}
    A_i = \text{Softmax}\left(\frac{(Q_{proto} W_i^Q)(F_{inst} W_i^K)^\top}{\sqrt{d_k}}\right)
\end{equation}
其中，$W_i^Q, W_i^K \in \mathbb{R}^{C_5 \times d_k}$ 为线性投影矩阵，$d_k$ 为每个头的特征维度。
最终生成具有实例区分性的动作实例感知特征 $Q_{inst}$：
\begin{equation}
    Q_{inst} = \text{MHA}(Q_{proto}, F_{inst}, F_{inst}) \in \mathbb{R}^{N \times C_5}
\end{equation}
通过这种交叉注意力机制，每个查询原型能够自适应地聚合$F_{inst}$中不同时空位置的显著性特征，
从而将视频片段中潜在的多实例信息注入到动作查询中。

接下来，时序拓展环节负责将动作实例感知特征$Q_{inst}$在时间维度上进行扩展，以生成贯穿整个
时序的动作管查询。具体来说，首先将 $Q_{inst}$ 在时间维度上进行复制扩展，得到初始的动作管
查询$Q_{temp} \in \mathbb{R}^{N \times T \times C}$。然而，此时的$Q_{temp}$缺失
时序信息，模型难以感知动作在不同帧的动态变化。为此，模型引入了时序位置编码（Temporal Positional Embedding） $P_{temp}$，
将其与$Q_{temp}$进行加和运算，最终生成了包含动作实例先验且具备时序位置信息的动作管查询$Q_{tube} \in \mathbb{R}^{N \times T \times C}$。

\section{实例特征引导的自适应采样模块}

在得到实例相关的动作管查询$Q_{tube}$后，时空动作解码器需要基于这些查询从多尺度特征图
中提取与当前动作实例高度相关的时空特征。为了增强对复杂运动场景下的时空上下文特征挖掘能力，
本节设计了实例特征引导的自适应采样模块（IASM），其结构如图 \ref{Fig4-4} 所示。该模块通过
生成与动作实例特征相关的采样点偏移量，实现对多尺度时空特征图的自适应采样，从而灵活地聚焦于
与动作高度相关的区域，提升模型对局部细节和动态变化的感知能力。
\begin{figure}[!htbp]
    \centering\includegraphics[width=0.7\textwidth]{figures/工作2模块2.png}
    \caption{实例特征引导的自适应采样模块}\label{Fig4-4}
\end{figure}

对视觉特征进行自适应采样的思想在计算机视觉领域已有广泛应用（如 DCN、Deformable DETR、DAT）。
通过预测采样点偏移量引导模型关注重要区域，不仅可以扩大有效感受野、提高信噪比，还能更好地关注时空上下文，
而通过实例特征引导的采样策略，更能确保采样点与当前动作实例高度相关。
首先，与现有范式（如 TubeR、STAR）相同，在动作管查询进入 IASM 之前，首先通过一个正交时空自注意力
模块（FSA）进行内部交互，以增强查询间的信息传递与协同。IASM接收经过FSA增强后的动作管查询
$Q_{tube} \in \mathbb{R}^{N \times T \times C}$ 以及多尺度时空特征图$\mathcal{S} =\{S_i\}_{i=3}^{5}$作为输入。
随后，为了实现自适应采样，IASM 需要生成采样点的参考位置和偏移量。对于第$i$层特征图，首先定义动作管查询
在时间步$t$的参考点（Reference Point）为$P_{ref} \in \mathbb{R}^{N \times T \times 2}$。该点由动作管特征
通过一个线性层回归获得，代表了当前实例在每一帧的潜在中心位置。接着，模块通过一个轻量级的偏移预测网络（Offset Network）
来生成采样偏移量，如图 \ref{Fig4-4} 所示，该网络由 Linear-GELU-Linear 层构成，作用于查询特征的通道维度：
\begin{equation}
    \Delta P_i = \text{OffsetNetwork}i(Q{tube})
\end{equation}
其中，$\Delta P_i \in \mathbb{R}^{N \times T \times n \times 2}$ 表示$N$个实例在$T$个时间步上、每个步长的$n$个采样点的坐标偏移。
接下来，模块在特征图$S_i$上执行自适应采样。对于每个动作管查询在时刻$t$的第 $k$ 个采样点，其绝对采样位置计算为
$P_{sample} = \phi(P_{ref} + \Delta P_{ik})$（$\phi$ 为坐标归一化函数）。模块通过双线性插值从$S_i$中提取该
位置的时空特征，得到层级采样特征 $V_{sampled}^i$：
\begin{equation}
    V_{sampled}^i = \text{BilinearSample}(S_i, P_{ref} + \Delta P_{i}) \in \mathbb{R}^{N \times T \times n \times C}
\end{equation}
通过这种实例特征引导的自适应采样策略，IASM 能够基于动作管查询预测的参考轨迹，灵活地从多尺度特征图中抓取与当前动作高度相关的局部细节，
显著提升了模型对复杂运动场景的感知能力。

\section{解耦时空交叉注意力模块}
\begin{figure}[!htbp]
    \centering\includegraphics[width=0.9\textwidth]{figures/工作2模块3.png}
    \caption{解耦时空交叉注意力模块}\label{Fig4-5}
\end{figure}
接下来，对于采样特征 $V_{sampled} \in \mathbb{R}^{N \times T \times n \times C}$ 和动作管查询
$Q_{tube} \in \mathbb{R}^{N \times T \times C}$，模型需要将二者进行有效融合，以便将关键的视觉上下文信息注入到
动作管查询中。为此，本节设计了解耦时空交叉注意力模块（DSTAM），其结构如图 \ref{Fig4-5} 所示。

不同于（deformable detr）所采用地线性加权来进行特征融合，
为了能够基于候选特征自适应地从这$n$个候选点中筛选并聚合最关键的视觉信息，并进一步建模时序依赖，本节设计了
时空解耦注意力模块（DSTAM），该模块包含级联的空间交叉注意力（SCA）和时序自注意力（TSA），SCA和TSA都是基于多头注意力模块。
首先，SCA旨在将$n$个离散的采样特征聚合为紧凑的实例特征，对于动作管查询 $Q_{tube} \in \mathbb{R}^{N \times T \times C}$ 
和未聚合的采样特征 $V_{sampled} \in \mathbb{R}^{N \times T \times n \times C}$。在SCA阶段，DSTAM将时空维度展平
为批次维度，重点关注实例与采样点之间的局部交互。具体而言，我们将 $Q_{tube}$ 重塑为 $N \cdot T \times 1 \times C$ 
作为查询，将 $V_{sampled}$ 重塑为 $N \cdot T \times n \times C$ 作为键和值。SCA的计算过程如下：
\begin{equation}
    Q_{spatial} = \text{SCA}(Q_{tube}, V_{sampled}, V_{sampled}) + Q_{tube}
\end{equation}
其中，输出特征 $Q_{spatial} \in \mathbb{R}^{N \cdot T \times 1 \times C}$，并在计算后恢复为$N \times T \times C$。
在这一过程中，注意力机制会计算查询与每个采样点之间的语义相似度，从而赋予包含显著动作细节的采样点更高的权重。
这弥补了仅依赖几何位置采样的不足。
随后，聚合后的特征进入TSA环节，以捕捉长时时序依赖。TSA将$Q_{spatial}$重塑为$N \times T \times C$，
此时每个实例在时间轴上形成一个长度为$T$的序列。TSA在该序列上执行全时序交互：
\begin{equation}
    Q_{temporal} = \text{TSA}(Q_{spatial}, Q_{spatial}, Q_{spatial}) + Q_{spatial}
\end{equation}
最后，通过前馈神经网络（FFN）处理得到最终更新的动作管查询 $Q_{tube}^{updated}$。
通过这种设计，DSTAM不仅完成了从离散采样点到实例特征的高效聚合，还有效地注入了时序上下文信息。

\section{损失函数}


\section{实验结果与分析}
\subsection{数据集介绍}

\subsection{实验设置}

\subsection{评价指标}

\subsection{对比实验结果}
（1） 小运动
表1
（2） 中运动
表2
（3） 剧烈运动
表3
（4） 环境相关运动
表4
（5） 全部
表5
\subsection{消融实验结果}
baseline
base+1
表+图+热图
base+2
表+图+采样点图
base+3

\section{本章小结}






