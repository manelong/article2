\chapter{基于语义增强的体育时空动作检测算法研究} 
\label{cha:thirdsection}

与日常行为场景不同，体育场景下的动作通常具有高度的专业性和规则依赖性，
单一的视觉特征往往难以充分捕捉动作背后的规则约束和上下文关系，往往需要
结合深层的语义信息和领域专家的先验知识，才能准确理解动作含义并完成精确辨析。
为此，本章提出了一种基于双粒度语义增强的体育时空动作检测算法，
该方法通过构建基于语义对齐的双粒度体育多模态知识库，为时空动作检测算法提供准确
语义信息，并设计了一种知识检索融合模块，有效地将领域专业知识注入时空动作检测框架中，
显著提升了模型对复杂体育动作的检测能力。

\section{引言}

由于时空动作检测需要同时实现动作的分类、空间定位和时间定位任务，
所以早期的研究主要致力于如何提取更加鲁棒有效的时空特征以提升检测性能，
例如，EVAD和VideoMAE等工作通过设计时空自掩码机制来获得更具鲁棒性的时空表征。
然而，时空动作检测不仅依赖于底层的视觉特征，人体的运动模式、场景上下文以及
动作的深层语义同样对检测结果起着决定性作用，
在面对复杂的体育场景时，这些单纯依赖视觉模态的方法仍然存在局限性。

相比于日常场景，体育场景的时空动作检测面临着更为严峻的挑战：
（1）细粒度动作的视觉差异微弱。许多体育动作在视觉外观上高度相似，主要区别
在于动作意图或力度等隐性特征。例如，在排球场景中，“扣球”和“吊球”在起跳和
挥臂的初期轨迹上几乎一致，其主要区别在于击球瞬间的力度和击球后球的运动状态。
% ，单纯依赖像素级的视觉特征难以对这两类动作进行准确界定。
（2）动作定义的强规则约束性。体育动作的判定往往严格遵循特定的竞技规则和技术标准，
而非简单的肢体运动。以体操运动中的“俯卧撑”为例，其标准定义要求运动员在腾空阶段
呈屈体姿势，躯干与双腿间形成约60°夹角，且落地时需呈伸展后撑姿势。这种包含特定角度、
时序逻辑和接触状态的判别性语义，构成了体育动作的核心特征。

因此，单一的视觉特征往往难以捕捉这种隐含在规则背后的高层语义，从而限制了
模型在复杂规则场景下的检测效果，需要结合深层的语义信息和领域专家的先验知识，才能
准确理解复杂动作的含义并完成动作解析。

近年来，随着多模态大模型（如CLIP, BLIP, GPT-4, Qwen等）的快速发展，多模态特征融合
技术在诸多视觉感知任务中展现出卓越性能。这些大模型通过大规模预训练，能够提取
包含丰富语义的“视觉-文本”联合特征表示，在很多视觉感知下游任务中（grounding dino、lisa
、lisa++）发挥着重要作用。多模态
大模型强大的泛化能力与场景理解能力，与复杂体育动作检测的需求高度契合，部分研究已开始
探索将其应用在时空动作检测任务中，例如PoSTAL通过将篮球运动员的衣着颜色和号码作为文本提示
输入BLIP模型，利用文本编码引导模型关注特定视觉区域；HCBS则面向足球场景，利用
LLava生成从粗到细的多层级问答，并将文本编码特征与视觉特征融合来提升模型的检测性能。

然而，这些方法仍存在以下局限性：
（1）缺乏领域专业信息的有效引导。现有方法多依赖通用的大模型生成描述，但是生成式模型容易
产生不准确的回答，进而误导动作检测；或仅使用简单的标签、外观特征（如球衣颜色）作为提示，
忽略了体育动作背后复杂的规则约束和技术规范，导致多模态信息无法有效补充视觉特征的不足。
（2）多模态联合特征利用不充分。现有的方法大多数仅利用多模态大模型中的文本编码器所
输出的描述文本嵌入，而忽略了多模态模型在预训练阶段习得的深层“视频-文本”联合
特征所蕴含的丰富语义，仅利用文本嵌入忽视了多模态大模型的跨模态理解能力。

综上所述，为了解决上述问题，本章提出了一种基于语义增强的体育时空动作检测算法（英文。。。）。
该算法的主要工作是：（1）结合体育领域的专业知识，构建高可信度的多模态知识库；
（2）设计有效的检索和融合机制，利用多模态知识嵌入辅助时空动作检测。

具体而言，为了引入精确的领域知识，本章首先对现有数据集动作类别的专业定义进行了详尽搜集，
并以此构建了一个“场景-文本”与“运动-文本”的双粒度多模态知识库，这一设计考虑了体育动作
的特性差异：针对篮球投篮（如二分球、罚球）等依赖场地信息的动作，知识库侧重补充场景
上下文特征；而针对体操（如旋转、跳跃）等依赖肢体姿态的动作，知识库则侧重增强运动特征。
对于每一类动作原型，该知识库提供“场景-文本”与“运动-文本”的双粒度知识，确保了信息的互补性，
并通过多动作原型选择策略提高了知识库的质量。
在此基础上，本章设计了一种知识检索融合模块（英文。。。），能够有效地检索知识库中相关的知识
并充分融合到检测模型中，从而提升模型检测性能。

本章的主要贡献总结如下：

（1）提出了一种基于知识增强的时空动作检测算法。 
针对体育场景下视觉特征辨识度低、规则约束强的难点，本章创新性地引入了
外部知识库作为语义先验，通过显式的检索并融合知识库信息，有效提升了
模型对复杂体育运动的理解能力。

（2）提出了一种多原型双粒度多模态知识库构建方法。
通过结合Qwen-VL大模型与领域专家知识，构建了包含“全局场景”与“局部运动”的
双流知识库，并通过动作原型筛选，为检测模型提供了高可信的外部知识。

（3）设计了知识检索融合模块。通过设计一个双路知识检索模块
和一个基于多头注意力的融合模块，能够自适应地从双粒度知识库中检索相关
知识，并将其有效融合到时空动作检测框架中。

本章的组织结构安排如下：3.1节首先回顾基于外部知识增强的时空动作检测研究现状，
并阐述本章的研究动机和思路；3.2节详细介绍了基于语义引导的双粒度体育知识库的构建；
3.3节简要介绍了基于多模态特征增强的时空动作检测模型的整体架构；
3.4节深入阐述了知识检索融合模块的设计；3.5节介绍模型的损失函数设计；
3.6节介绍实验设置，并在UCF101-24和MultiSports数据集上进行对比实验与消融分析；
3.7节对本章工作进行总结。

\section{基于语义对齐的双粒度体育多模态知识库构建}
\subsection{知识库构建动机与思路}

在体育时空动作检测任务中，单一的视觉特征往往难以充分捕捉动作背后的规则约束和上下文关系。
为此，引入外部多模态知识库作为语义先验，能够有效弥补视觉模态在理解复杂体育规则方面的不足。 
然而，构建一个高质量的体育多模态知识库面临诸多挑战：
（1）知识的专业性与准确性。体育动作通常具有严格的技术规范和规则约束，
仅依赖通用的生成式模型生成描述，往往难以保证信息的准确性和专业性。
（2）体育动作知识的多样性。准确判别一个体育动作有点需要对场景上下文有深入的理解，
有的则需要感知动作本身的运动特点，不同类型的动作侧重不同方面的知识。
（3）知识库知识的丰富度。直接将每个类别的多模态特征进行归一化处理获得唯一的原型表示，
会导致知识库特征过度平滑，进而影响模型的泛化能力。

针对上述挑战，本章提出了一种基于语义对齐的双粒度体育多模态知识库构建方法。
具体来说：为了保证知识的专业性与准确性，本章结合领域专家知识与多模态大模型的理解能力，
为每一类动作设计了静态的专业文本描述，避免了生成式模型可能带来的“幻觉”问题；
针对体育动作知识的多样性的问题，本章设计了双粒度的知识表示，对于每一类动作，
分别构建了“场景-文本”与“运动-文本”两种粒度的描述，以覆盖不同类型动作的特征需求；
最后，为了提升知识的丰富度，本章引入了基于 通过多动作原型选择策略，提升知识库的多样性与代表性。

\subsection{知识库构建方法}

（1）知识库构建整体流程

本节介绍双粒度体育多模态知识库构建的整体流程，如下图所示，知识库的构建流程主要包括以下四个步骤：
首先是动作描述的收集与提示设计，针对数据集中每个动作类别，本章结合领域专家知识与多模态大模型特征，
设计了静态的专业文本描述，确保信息的准确性和专业性；然后是多模态特征的提取与预处理，利用Qwen-VL大模型，
分别提取每个动作类别的“场景-文本”与“运动-文本”两种粒度的多模态特征；最后是通过基于密度峰值聚类的多动作原型
选择策略，选取每个类别的Top-K个代表性原型作为最终的知识库，确保知识库的多样性与代表性。
本节将基于UCF101-24和MultiSports数据集的双粒度体育多模态知识库。

（2）高质量动作描述的收集

由于直接使用多模态大模型生成描述容易出现不准确的回答，所以本节使用静态文本描述
方法，可以保证知识库中描述的准确性和专业性。
具体来说，对于UCF101-24数据集，由于动作的差异性相对比较明显，本节首先利用
多模态大模型Qwen-VL生成每个动作类别的专业描述文本，并通过人工筛选与修正，
确保描述的准确性和专业性；
而对于Multisports数据集，由于动作专业性更高类别更加丰富，本节利用Multisports的
官方标注手册，收集每个动作类别的技术规范与规则定义，确保描述的权威性和专业性。
以下是部分动作类别的描述示例：

\begin{table}[htbp]
    \centering
    \caption{UCF101-24数据集部分动作类别描述示例}
    % {lX}: 第一列左对齐(l)，第二列自动换行(X)
    \begin{tabularx}{\textwidth}{lX}
      \toprule
      \textbf{动作名称} & \textbf{动作描述} \\ % 建议加上表头
      \midrule
      Biking & A person riding a bicycle outdoors, pedaling continuously while balancing on two wheels on roads or trails. \\
      \midrule
      IceDancing & Skaters gliding on an ice rink, performing choreographed dance moves, spins, and lifts. \\
      \midrule
      Skiing & A person gliding down a snow-covered slope on skis, using poles for balance and turning by shifting body weight. \\
      \bottomrule
    \end{tabularx}%
    \label{Tab3-1}%
  \end{table}%

\begin{table}[htbp]
    \centering
    \caption{MultiSports数据集部分动作类别描述示例}
    % {lX}: 第一列保持紧凑左对齐，第二列占据剩余空间并换行
    \begin{tabularx}{\textwidth}{lX}
      \toprule
      \textbf{动作名称} & \textbf{动作描述} \\
      \midrule
      Aerobic Turn &  All exercises requiring turns must demonstrate complete rotations on the ball of the foot. Turns are completed when the heel of the turning foot touches the floor.\\
      \midrule
      Volleyball Dink & Lightly tap the ball over the net to an area on the opponent’s side of the court that is not being guarded or occupied by a defensive player. Start: Any foot leaves the ground. End: Any foot touches the ground. \\
      \midrule
    %   football Throw & The player throws the ball from out of the field and the goalkeeper throws the ball. Start: Upper arms swing forward. End: Upper arms are below the horizontal plane.\\
    %   \midrule
      Basketball Pass-inbound& The player passes the ball from the boundary lines to restart the play. Start: The player begins to push the ball outwards with his arms. End: The ball leaves both hands of the player.\\
      \bottomrule
    \end{tabularx}%
    \label{Tab3-2}%
\end{table}%


（2）双粒度提示模板设计及多模态知识提取

随后，本节设计了双粒度的视频提示模板，旨在让Qwen-vl生成联合特征时
更加有不同的侧重点。具体来说，“场景-文本”提示模板强调动作发生的空间环
境与布局信息；“运动-文本”提示模板，突出动作的技术规范与姿态要求。如下所示：

“场景-文本”的提示模板：
\begin{verbatim}
Sense_TEMPLATE = (
    "Analyze the environmental context of the action '{action}'. "
    "Based on the definition: '{desc}', identify the scene setting"
)
\end{verbatim}

“运动-文本”的提示模板：
\begin{verbatim}
Move_TEMPLATE = (
        "Analyze the body motion of the action '{action}'. "
        "Based on the definition: '{desc}', describe the key body parts, "
        "motion trajectory, and start/end states. "
    )
\end{verbatim}

本节使用Qwen3-vl-2B版本的多模态大模型，对UCF101-24来说，将最大处理帧数限制为32帧，
对MultiSports数据集来说，将最大处理帧数限制为64帧，分别提取每个动作实例的多模态特征，
在提取特征过程中仅使用训练集涉及的样本数据，防止数据泄露。

下图分别为UCF101-24和Multisports数据集中不同动作类别的“场景-文本”与“运动-文本”特征
的t-SNE可视化结果，可以看出，不同类别的多模态特征在特征空间中呈现出良好的分离度，为
后续的动作检测任务提供了有力支持。

（3）多知识原型选择

通过Qwen-vl得到的知识库容量极大，如果直接将所有样本特征纳入知识库，会导致检索效率极低，影响模型
性能，通常的做法是对同一类别的多模态特征进行归一化处理，获得唯一的知识原型表示，但是，
根据imp、Tip-adapt的相关工作可知，同一个概念本身具有多样性，如果简单将同一类别的
多模态特征进行归一化获得唯一的原型表示，可能导致知识过于平滑，缺乏多样性，进而影响模型的泛化能力。对于体育
动作而言，不同的视角、运动员个体差异以及动作执行方式本身就具有多样性，为此，本节通过基于密度
峰值聚类的多动作原型选择策略，从每个动作类别中选取多个代表性样本作为该类别的原型，以此提高知识库知识的丰富度。

具体而言，本节采用基于密度峰值聚类（DPC）的策略为每个动作类别选择Top-K个知识原型，DPC在选择
聚类中心时，同时考虑了样本的代表性和区分度，通过计算样本间的距离矩阵，评估每个样本的局部密度和相对距离，
从而选取既能代表类别特征又能区分其他类别的样本作为聚类中心。对于每一类动作的
$N$个特征向量 $X = \{x_1, x_2, ..., x_N\}$，首先计算两两之间的余弦距离矩阵 
$d_{ij} = 1 - \cos(x_i, x_j)$。在此基础上，计算每个样本的局部密度 $\rho_i$ 与 相对距离 $\delta_i$。
局部密用来保证代表性$\rho_i = \sum_{j \neq i} \chi(d_{ij} - d_c)$其中$\chi(\cdot)$为指示函数，
$d_c$ 为截断距离，本节将其设置为5\%。较大的$\rho_i$表明样本位于高密度区域，能够有效抑制离群噪声。
相对距离用于保证区分度$\delta_i = \min_{j: \rho_j > \rho_i} (d_{ij})$
特别地，对于密度最大的点，设 $\delta_i = \max_j(d_{ij})$。
该项用于惩罚那些虽然密度高但距离更高密度点过近的冗余样本。
最终，通过计算决策得分$\gamma_i = \rho_i \times \delta_i$，选取$\gamma$值
最大的$K$个真实样本作为该动作类别的语义原型。

下图是通过DPC选择特征原型的可视化展示，本节将获取到的特征进行t-SNE降维可视化，其中五角星形为所
选中的特征原型，分别对“场景-文本”特征和“运动-文本”采样数个动作类别进行展示，可以看出所选取的
特征原型均大致处于特征的密度中心，且不同原型之间具有较好的区分度，能够有效代表该类别的多样性特征。

\section{多模态特征增强的时空动作检测模型整体架构}

如图所示，本章基于双粒度体育多模态知识库，设计了一种多模态特征增强的时空动作检测模型，
该模型以Tuber为基准模型，通过引入语义注入交叉注意力模块（USI-CA），实现了对知识库
特征的检索和融合，显著提升了模型对复杂体育动作的理解与检测能力。

具体来说，首先在时空特征提取阶段，对于输入视频片段$X \in \mathbb{R}^{T \times H \times W \times 3}$，
模型首先利用预训练的视频编码器对输入视频序列进行时空特征提取，并通过堆叠多个Transformer编码器层，
对提取的时空特征进行进一步编码，以捕捉更丰富的时空上下文信息，特征表示为
$S \in \mathbb{R}^{t \times h \times w \times c_f}$，其中$t$为时间维度，$h,w$为空间维度，$c_f$为特征通道数。
与Tuber的设置相同，接着，在时空特征解码阶段，模型首先会基于预定义的动作管查询向量
$Q_{tube} \in \mathbb{R}^{N \times T \times c_q}$进行正交自注意力计算（FSA），
以分别捕捉动作管之间的关系和时序信息。随后，结合更新后的动作管查询向量，会输入到本章
所设计的语义查询融合模块（USI-CA）中，在该模块中，模型会自适应地从双粒度多模态知识库中
检索出Top-K个最相关的多模态特征，并通过多头注意力机制将其动态注入到动作管查询向量中，
由此生成了增强的动作管特征表示$Q_{enhanced} \in \mathbb{R}^{N \times T \times c_q}$。
最后，将增强后的动作管特征与编码后的时空特征$S$进行交叉注意力计算，提取动作相关的时空特征，
经过解码器的多层迭代更新后，最终的动作管特征$Q_{enhanced}$被送入检测头，前馈神经网络FFN构成：一个动作分类头，用于预测动作实例的类别，输出维度为
$\hat{y}_{cls} \in \mathbb{R}^{N \times (K+1)}$（$K$ 为类别数）；
时序定位头和空间定位头分别负责时序边界判断和矩形框回归，前者输出时序边界概率
$\hat{y}_{bound} \in \mathbb{R}^{N \times T}$，后者输出归一化的时空边界框坐标
$\hat{y}_{box} \in \mathbb{R}^{N \times 4 \times T}$，从而实现对时空动作的精确定位与识别。

\section{语义注入交叉注意力模块}

对于该模块，主要作用是实现从双粒度多模态知识库中自适应地检索并注入关键语义信息，
以增强时空动作检测模型的表征能力。该模块的设计包括两个关键部分：多模态特征检索机制和语义特征融合机制。

\subsection{双分支检索模块}

为了从知识库中有效地检索出与当前视觉特征最相关的语义信息，本节设计了一种基于对比
学习的双分支检索模块，该模块包含两个检索网络，分别用于“场景-文本”与“运动-文本”知识库的特征检索。
在训练阶段，基于匈牙利算法正负样本匹配的结果，优化检索网络参数，使得视觉特征与对应类别的多模态原型
在隐空间中更加接近，在推理阶段，对于每个查询向量，计算其与知识库中所有原型的相似度，
并选取Top-K个最相关的原型作为检索结果。

\subsection{知识融合模块}

为了将检索到的多模态语义特征有效地注入到时空动作检测模型中，本节设计了一种基于多头注意力机制的语义特征融合机制。
该机制通过计算视觉特征与检索到的多模态特征之间的注意力权重，
实现了语义信息的动态融合。具体来说，首先将动作管查询向量作为查询（Q），
将检索到的多模态特征作为键和值，在训练阶段，通过优化注意力权重，
使得模型能够自适应地关注与当前视觉特征最相关的语义信息，从而提升动作特征的表达能力。具体流程如下图所示：
在推理阶段，将检索模块得到的Top-K个多模态特征与视觉特征进行多头注意力计算，
得到融合后的增强特征，并将其输入到时空特征解码器中，提升模型的检测性能。
模块设计如下图所示：

\section{损失函数设计}

为了有效地训练基于多模态特征增强的时空动作检测模型，本节设计了一种综合性的损失函数，
包括传统的边界回归损失、分类损失以及新引入的语义原型对齐损失。

\section{实验结果与分析}
\subsection{实验设置}

本章的实验均在UCF101-24和MultiSports数据集上进行评估，以验证双粒度多模态知识库
对时空动作检测性能的提升效果。本章模型以使用在CSN152为骨干网络的Tuber为基准模型，
CSN152在Kinetics-400数据集上进行预训练，其中时空特征编码块和动作解码块的个数均设置为6。
所用模型使用PyTorch 2.1.0和Python 3.8实现，并在RTX 4090 GPU上完成训练，其中
动作管查询的个数$N$设置为32，使用AdamW优化器进行训练，骨干网络的初始学习率设
为$1\text{e-}5$，解码器的初始学习率设为$1\text{e-}4$，权重衰减设为0.01。
输入视频进行等比例缩放和填充，保持短边被设置为256，视频输入的帧数$T$设置为32。

\subsection{对比实验结果}

（1）时空动作检测算法对比


（2）大模型辅助的时空动作检测算法对比

\subsection{消融实验结果}

（1）双粒度多模型知识库

（2）知识检索融合模块

检索的topk图

融合机制

加和、concat、门控、MHA

\subsection{误差分析}


\section{本章小结}


